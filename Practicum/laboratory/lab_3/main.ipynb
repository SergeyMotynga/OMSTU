{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea46785",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygad\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "import pyswarms as ps\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import neat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2270661c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('csgo_filtred.csv')\n",
    "\n",
    "y = data['bomb_planted']\n",
    "X = data.drop(columns=['bomb_planted'], axis=1)\n",
    "mapping = {\n",
    "    'de_inferno': 1,\n",
    "    'de_dust2': 2,\n",
    "    'de_nuke': 3,\n",
    "    'de_mirage': 4,\n",
    "    'de_overpass': 5,\n",
    "    'de_train': 6,\n",
    "    'de_vertigo': 7,\n",
    "    'unknown': 8,\n",
    "    'de_cache': 9\n",
    "}\n",
    "X['map'] = X['map'].map(mapping)\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "oversample = SMOTE()\n",
    "transformed_X, tranformed_y = oversample.fit_resample(X, y)\n",
    "X, y = transformed_X, tranformed_y\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.001, train_size=0.005, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c2e02e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = joblib.load(r'models\\naive_bayes')\n",
    "dt = joblib.load(r'models\\dt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5eed51a",
   "metadata": {},
   "source": [
    "# PyGAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "755947c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\motyn\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pygad\\pygad.py:724: UserWarning: The percentage of genes to mutate (mutation_percent_genes=10) resulted in selecting (0) genes. The number of genes to mutate is set to 1 (mutation_num_genes=1).\n",
      "If you do not want to mutate any gene, please set mutation_type=None.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие параметры DT: [16, 10, 4] Accuracy: 0.970873786407767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\motyn\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pygad\\pygad.py:724: UserWarning: The percentage of genes to mutate (mutation_percent_genes=10) resulted in selecting (0) genes. The number of genes to mutate is set to 1 (mutation_num_genes=1).\n",
      "If you do not want to mutate any gene, please set mutation_type=None.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучший var_smoothing для NB: 2.5945886040497872e-08 Accuracy: 0.9223300970873787\n"
     ]
    }
   ],
   "source": [
    "def fitness_dt(ga_instance, solution, solution_idx):\n",
    "    max_depth, min_split, min_leaf = map(int, solution)\n",
    "    model = DecisionTreeClassifier(\n",
    "        max_depth=max_depth,\n",
    "        min_samples_split=min_split,\n",
    "        min_samples_leaf=min_leaf,\n",
    "        random_state=42\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "    return accuracy_score(y_test, preds)\n",
    "\n",
    "ga_dt = pygad.GA(\n",
    "    num_generations=40,\n",
    "    sol_per_pop=30,\n",
    "    num_parents_mating=10,          \n",
    "    num_genes=3,\n",
    "    gene_space=[\n",
    "        {'low': 1,  'high': 20},\n",
    "        {'low': 2,  'high': 20},\n",
    "        {'low': 1,  'high': 20}\n",
    "    ],\n",
    "    fitness_func=fitness_dt,\n",
    "    parent_selection_type=\"sss\",\n",
    "    crossover_type=\"single_point\",\n",
    "    mutation_type=\"random\"\n",
    ")\n",
    "ga_dt.run()\n",
    "best_dt_solution, best_dt_fitness, _ = ga_dt.best_solution()\n",
    "print(\"Лучшие параметры DT:\", list(map(int, best_dt_solution)), \"Accuracy:\", best_dt_fitness)\n",
    "\n",
    "\n",
    "def fitness_nb(ga_instance, solution, solution_idx):\n",
    "    var_smoothing = 10 ** solution[0]\n",
    "    model = GaussianNB(var_smoothing=var_smoothing)\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "    return accuracy_score(y_test, preds)\n",
    "\n",
    "ga_nb = pygad.GA(\n",
    "    num_generations=30,\n",
    "    sol_per_pop=20,\n",
    "    num_parents_mating=5,           \n",
    "    num_genes=1,\n",
    "    gene_space=[{'low': -12, 'high': -6}],\n",
    "    fitness_func=fitness_nb,\n",
    "    parent_selection_type=\"sss\",\n",
    "    crossover_type=\"single_point\",\n",
    "    mutation_type=\"random\"\n",
    ")\n",
    "\n",
    "ga_nb.run()\n",
    "best_nb_solution, best_nb_fitness, _ = ga_nb.best_solution()\n",
    "best_var_smoothing = 10 ** best_nb_solution[0]\n",
    "print(\"Лучший var_smoothing для NB:\", best_var_smoothing, \"Accuracy:\", best_nb_fitness)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6cf6f5e",
   "metadata": {},
   "source": [
    "# PySwarms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "58b2c81b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-02 23:37:00,865 - pyswarms.single.global_best - INFO - Optimize for 100 iters with {'c1': 0.5, 'c2': 0.3, 'w': 0.9}\n",
      "pyswarms.single.global_best: 100%|██████████|100/100, best_cost=0.0291\n",
      "2025-05-02 23:37:21,104 - pyswarms.single.global_best - INFO - Optimization finished | best cost: 0.029126213592232997, best pos: [17.3727466   7.47608944  5.00632927]\n",
      "2025-05-02 23:37:21,110 - pyswarms.single.global_best - INFO - Optimize for 80 iters with {'c1': 0.5, 'c2': 0.3, 'w': 0.9}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DT params: [17, 7, 5] accuracy: 0.970873786407767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pyswarms.single.global_best: 100%|██████████|80/80, best_cost=0.0777\n",
      "2025-05-02 23:37:24,105 - pyswarms.single.global_best - INFO - Optimization finished | best cost: 0.07766990291262132, best pos: [-6.15701734]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB var_smoothing: 6.965986979104352e-07 accuracy: 0.9223300970873787\n"
     ]
    }
   ],
   "source": [
    "def dt_objective(params):\n",
    "    n_particles = params.shape[0]\n",
    "    losses = np.zeros(n_particles)\n",
    "    for i in range(n_particles):\n",
    "        max_depth, min_split, min_leaf = map(int, params[i])\n",
    "        model = DecisionTreeClassifier(\n",
    "            max_depth=max_depth,\n",
    "            min_samples_split=min_split,\n",
    "            min_samples_leaf=min_leaf,\n",
    "            random_state=42\n",
    "        )\n",
    "        model.fit(X_train, y_train)\n",
    "        preds = model.predict(X_test)\n",
    "        losses[i] = 1.0 - accuracy_score(y_test, preds)\n",
    "    return losses\n",
    "\n",
    "options_dt = {'c1': 0.5, 'c2': 0.3, 'w': 0.9}\n",
    "bounds_dt = (np.array([1, 2, 1]), np.array([20, 20, 20]))\n",
    "\n",
    "optimizer_dt = ps.single.GlobalBestPSO(\n",
    "    n_particles=30,\n",
    "    dimensions=3,\n",
    "    options=options_dt,\n",
    "    bounds=bounds_dt\n",
    ")\n",
    "\n",
    "best_cost_dt, best_pos_dt = optimizer_dt.optimize(\n",
    "    dt_objective, iters=100, verbose=True\n",
    ")\n",
    "\n",
    "best_dt_params = list(map(int, best_pos_dt))\n",
    "best_dt_acc = 1.0 - best_cost_dt\n",
    "print(\"DT params:\", best_dt_params, \"accuracy:\", best_dt_acc)\n",
    "\n",
    "\n",
    "def nb_objective(params):\n",
    "    n_particles = params.shape[0]\n",
    "    losses = np.zeros(n_particles)\n",
    "    for i in range(n_particles):\n",
    "        log_vs = params[i][0]\n",
    "        var_smoothing = 10 ** log_vs\n",
    "        model = GaussianNB(var_smoothing=var_smoothing)\n",
    "        model.fit(X_train, y_train)\n",
    "        preds = model.predict(X_test)\n",
    "        losses[i] = 1.0 - accuracy_score(y_test, preds)\n",
    "    return losses\n",
    "\n",
    "options_nb = {'c1': 0.5, 'c2': 0.3, 'w': 0.9}\n",
    "bounds_nb = (np.array([-12.0]), np.array([-6.0]))\n",
    "\n",
    "optimizer_nb = ps.single.GlobalBestPSO(\n",
    "    n_particles=20,\n",
    "    dimensions=1,\n",
    "    options=options_nb,\n",
    "    bounds=bounds_nb\n",
    ")\n",
    "\n",
    "best_cost_nb, best_pos_nb = optimizer_nb.optimize(\n",
    "    nb_objective, iters=80, verbose=True\n",
    ")\n",
    "\n",
    "best_log_vs = best_pos_nb[0]\n",
    "best_nb_acc = 1.0 - best_cost_nb\n",
    "best_var_smoothing = 10 ** best_log_vs\n",
    "print(\"NB var_smoothing:\", best_var_smoothing, \"accuracy:\", best_nb_acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731722b2",
   "metadata": {},
   "source": [
    "# NEAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "63261884",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((40, 14), (1144, 12))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_data = pd.read_csv('cars_50_pairs_9_n_feature.csv')\n",
    "big_data = pd.read_csv('cars_1430_pairs_8_n_feature.csv')\n",
    "\n",
    "y_small = small_data['collision']\n",
    "X_small = small_data.drop(columns=['collision'], axis=1)\n",
    "\n",
    "y_big = big_data['collision']\n",
    "X_big = big_data.drop(columns=['collision'], axis=1)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_small = scaler.fit_transform(X_small)\n",
    "X_big = scaler.fit_transform(X_big)\n",
    "\n",
    "X_small_train, X_small_test, y_small_train, y_small_test = train_test_split(X_small, y_small, random_state=42, test_size=0.2, stratify=y_small)\n",
    "\n",
    "X_big_train, X_big_test, y_big_train, y_big_test = train_test_split(X_big, y_big, random_state=42, test_size=0.2, stratify=y_big)\n",
    "\n",
    "X_small_train.shape, X_big_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "65cea65b",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Missing configuration item: response_init_mean",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[44]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mneat\u001b[39;00m\n\u001b[32m      4\u001b[39m config_path = \u001b[33m\"\u001b[39m\u001b[33mconfig-neat.ini\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m config = \u001b[43mneat\u001b[49m\u001b[43m.\u001b[49m\u001b[43mConfig\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mneat\u001b[49m\u001b[43m.\u001b[49m\u001b[43mDefaultGenome\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mneat\u001b[49m\u001b[43m.\u001b[49m\u001b[43mDefaultReproduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mneat\u001b[49m\u001b[43m.\u001b[49m\u001b[43mDefaultSpeciesSet\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mneat\u001b[49m\u001b[43m.\u001b[49m\u001b[43mDefaultStagnation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig_path\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m pop = neat.Population(config)\n\u001b[32m     14\u001b[39m pop.add_reporter(neat.StdOutReporter(\u001b[38;5;28;01mTrue\u001b[39;00m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\motyn\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\neat\\config.py:189\u001b[39m, in \u001b[36mConfig.__init__\u001b[39m\u001b[34m(self, genome_type, reproduction_type, species_set_type, stagnation_type, filename)\u001b[39m\n\u001b[32m    187\u001b[39m \u001b[38;5;66;03m# Parse type sections.\u001b[39;00m\n\u001b[32m    188\u001b[39m genome_dict = \u001b[38;5;28mdict\u001b[39m(parameters.items(genome_type.\u001b[34m__name__\u001b[39m))\n\u001b[32m--> \u001b[39m\u001b[32m189\u001b[39m \u001b[38;5;28mself\u001b[39m.genome_config = \u001b[43mgenome_type\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparse_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgenome_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    191\u001b[39m species_set_dict = \u001b[38;5;28mdict\u001b[39m(parameters.items(species_set_type.\u001b[34m__name__\u001b[39m))\n\u001b[32m    192\u001b[39m \u001b[38;5;28mself\u001b[39m.species_set_config = species_set_type.parse_config(species_set_dict)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\motyn\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\neat\\genome.py:158\u001b[39m, in \u001b[36mDefaultGenome.parse_config\u001b[39m\u001b[34m(cls, param_dict)\u001b[39m\n\u001b[32m    156\u001b[39m param_dict[\u001b[33m'\u001b[39m\u001b[33mnode_gene_type\u001b[39m\u001b[33m'\u001b[39m] = DefaultNodeGene\n\u001b[32m    157\u001b[39m param_dict[\u001b[33m'\u001b[39m\u001b[33mconnection_gene_type\u001b[39m\u001b[33m'\u001b[39m] = DefaultConnectionGene\n\u001b[32m--> \u001b[39m\u001b[32m158\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDefaultGenomeConfig\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam_dict\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\motyn\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\neat\\genome.py:53\u001b[39m, in \u001b[36mDefaultGenomeConfig.__init__\u001b[39m\u001b[34m(self, params)\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;66;03m# Use the configuration data to interpret the supplied parameters.\u001b[39;00m\n\u001b[32m     52\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._params:\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m     \u001b[38;5;28msetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, p.name, \u001b[43mp\u001b[49m\u001b[43m.\u001b[49m\u001b[43minterpret\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# By convention, input pins have negative keys, and the output\u001b[39;00m\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m# pins have keys 0,1,...\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;28mself\u001b[39m.input_keys = [-i - \u001b[32m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m.num_inputs)]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\motyn\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\neat\\config.py:54\u001b[39m, in \u001b[36mConfigParameter.interpret\u001b[39m\u001b[34m(self, config_dict)\u001b[39m\n\u001b[32m     52\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     53\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.default \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m'\u001b[39m\u001b[33mMissing configuration item: \u001b[39m\u001b[33m'\u001b[39m + \u001b[38;5;28mself\u001b[39m.name)\n\u001b[32m     55\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     56\u001b[39m         warnings.warn(\u001b[33m\"\u001b[39m\u001b[33mUsing default \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[33m for \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{!s}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m.format(\u001b[38;5;28mself\u001b[39m.default, \u001b[38;5;28mself\u001b[39m.name),\n\u001b[32m     57\u001b[39m                       \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m)\n",
      "\u001b[31mRuntimeError\u001b[39m: Missing configuration item: response_init_mean"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import neat\n",
    "\n",
    "config_path = \"config-neat.ini\"\n",
    "config = neat.Config(\n",
    "    neat.DefaultGenome,\n",
    "    neat.DefaultReproduction,\n",
    "    neat.DefaultSpeciesSet,\n",
    "    neat.DefaultStagnation,\n",
    "    config_path\n",
    ")\n",
    "\n",
    "pop = neat.Population(config)\n",
    "pop.add_reporter(neat.StdOutReporter(True))\n",
    "stats = neat.StatisticsReporter()\n",
    "pop.add_reporter(stats)\n",
    "\n",
    "def eval_genomes(genomes, config):\n",
    "    for genome_id, genome in genomes:\n",
    "        net = neat.nn.FeedForwardNetwork.create(genome, config)\n",
    "        outputs = [net.activate(x) for x in X_train]\n",
    "        y_pred = [int(np.argmax(o)) for o in outputs]\n",
    "        genome.fitness = accuracy_score(y_train, y_pred)\n",
    "\n",
    "winner = pop.run(eval_genomes, n=30)\n",
    "\n",
    "best_net = neat.nn.FeedForwardNetwork.create(winner, config)\n",
    "test_outs = [best_net.activate(x) for x in X_test]\n",
    "y_pred_test = [int(np.argmax(o)) for o in test_outs]\n",
    "test_acc = accuracy_score(y_test, y_pred_test)\n",
    "print(f\"\\n=== NEAT Test Accuracy: {test_acc:.4f} ===\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

# EDA
**Многомерный анализ (Multivariate)**
	Чтобы увидеть являются ли одна или несколько из них предсказательными для определенного результата. **Предсказательные переменные** являются *независимыми переменными*, а **результат** - *зависимой переменной (выход, целевая переменная)*

**Этапы EDA**
	Этапы EDA могут варьироваться в зависимости от конкретной задачи и данных, но в целом процесс включает следующие *ключевые этапы:*
	1) **Определение цели анализа**.
		Четкое понимание целей анализа и вопросов, на которые необходимо ответить. Это может быть выявление *закономерностей*, поиск *аномалий*, или *подготовка данных*, для дальнейшего моделирования.
	2) **Сбор данных**.
		Сбор данных из различных источников, таких как базы данных, API, файлы (CSV, excel и т.д.) и др.
	3) **Предварительная обработка данных**.
		*Очистка данных:* удаление дубликатов, обработка пропущенных значений, исправление ошибок в данных.
		*Преобразование данных:* изменение формата данных, кодирование категориальных переменных, нормализация или стандартизация числовых признаков.
	4) **Анализ структуры данных.**
		Изучение размеров датасета, типов переменных и их распределений. Это может включать использование методов, таких как **info(), describe()** (библиотека Pandas)
	5) **Визуализация данных.**
		Построение графиков и диаграмм для *визуального представления данных.* Это может включать:
				1) Box Plots;
				2) Scatter Plots;
				3) HeatMaps;
		Визуализация помогает выявить *закономерности, аномалии, взаимосвязи между переменными*
	6) **Анализ статистических характеристик.**
		Вычисление основных статистических показателей, таких как *среднее, медиана, мода, дисперсия, стандартное отклонение*
		Оценка *корреляций* между переменными для понимания их взаимосвязей.
	7) **Выявление аномалий и выбросов.**
		Использование методов визуализации и статистических тестов для обнаружения выбросов или аномальных значений в данных
	8) **Формулирование гипотез.**
		На основе проведенного анализа формулирование гипотез о взаимосвязей между переменными или о поведении целевой переменной
	9) **Подготовка отчётов и выводов.**
		Документирование результатов анализа, создание отчётов с визуализациями и интерпретацией результатов.
	10) **Подготовка к моделированию.**
		На основе полученных знаний подготовка данных для дальнейшего анализа или построения моделей ML. Это может включать *выбор признаков, создание новых переменных* или дальнейшую *очистку данных.*

**Ключевые идеи:**
	**EDA** - *итеративный процесс*, который может потребовать возвращения к предыдущим этапам по мере получения новых инсайтов из данных.
	**Основная цель EDA** - лучше *понять* данные и *подготовить* их для последующего анализа или моделирования

**Размер и размерность данных.**
	**Размер данных** относится к числу объектов данных
	**Размерность данных** относится к числу атрибутов (признаков)

**Типы атрибутов (признаков)**
	![[Pasted image 20250214155256.png]]
**Типы данных**
	*Категориальные (или качественные) признаки* из неупорядоченного множества:
		1) бинарные: {0, 1}, {True, False}
		2) номинальные: \<city> {Vancouver, Burnaby, и т.д.}
		3) порядковые: 
	*Числовые (или количественные) признаки* из упорядоченного множества:
		4) числа
		5) непрерывные/действительные
	**Номинальные данные (Nominal Data)**
		*Возможные значения:* метки или названия вещей, категории. Например: пол, специальность, штат, цвет.
		Описывают характеристику *качественно,* а значения *не имеют порядка.*
		*Не количественные,* над ними *нельзя выполнять арифметические операции.*
		Можно вычислить:
			1) частота значений и наиболее частое значение.
		**Частота (Frecuency)**
			Номинальные и порядковые атрибуты обычно описывают частотами.
			*Частота значения* - это количество раз, когда значения встречаются в наборе данных.
			Иногда используется дробь или процент времени, когда значение появляется.
		Сбор данных посредством определения *частоты каких-либо вещей* либо строите *частоту в контексте доли от общего количества значений*
		*Двоичный атрибут:* частный случай номинальных значений **true/false, Pass/Fail, 0/1**
		*Симметричный:* оба символа имеют одинаковый вес, например, пол.
		*Асимметричный:* оба символа не одинаково важны, например, сдал/не сдал
		Для *визуализации номинальных данных* часто используют *круговую диаграмму, гистограмму*
	**Порядковые данные (Ordinal Data)**.
		Значения имеют *осмысленный порядок.*
			*Оценки:* A, B, C, D
			*Размеры порций:* маленькие, средние, большие
			*Оценки:* плохо, средне, отлично
		*Количественной разницей между двумя уровнями не обнаружено*
		**A** выше/лучше **B**, но *невозможно количественно определить*, насколько **A** выше **B** или является разница между ними такая же как между **B** и **C**
		Можно вычислить: 
			2) частота значений и наиболее частое значение
			3) среднее значение (mean)
	**Числовые признаки (Numeric Attributes)**
		*Количественные* данные, которые можно *измерить.*
		Можно *количественно определить разницу между двумя значениями.* Например: температуру, возраст, рост и т.д.
		Можно вычислить:
			1) частота значений и наиболее частое значение
			2) среднее значение (mean)
			3) среднее значение атрибута (average)
**Как можно преобразовать *категориальные признаки* в *числовые*?**
	![[Pasted image 20250214162004.png]]
	![[Pasted image 20250214162054.png]]
	![[Pasted image 20250214162736.png]]
**Основы описательной статистики (Statistical EDA)**
	**Описательная статистика** - раздел статистической науки, в рамках которого изучаются методы систематизации, описания и представления основных свойств данных.
	1) Оценки, дающие общую картину данных;
	2) Сводные статистические данные - это числа суммирующие свойства данных;
	3) Типичные свойства данных;
	4) *Разброс (spread) и распределение (distribution)* значений;
	5) *Зависимости* и *корреляции* между переменными.
	**Меры центральной тенденции**
		**Мера центральной тенденции* (Central Tendency)** - число, характеризующее выборку по уровню выраженности измеренного признака; описывает место концентрации или середину данных
		Три меры центральной тенденции:
			1) **Среднее** (среднее арифметическое всех значений)
			2) **Медиана** (серединное значение)
			3) **Мода** (наиболее частое наблюдение)
		Разница между медианой и средним значение существует из-за **рабостности (выбросоустойчивости)**
		Данные *распределены вокруг этого "центра"*
		Вычисляется для каждого атрибута
		Три распространенных типа местоположений:
			1) Среднее
			2) Мода
			3) Медиана
		*Эти меры не дают информации относительно*
			1) экстремальных значений в распределении данных
			2) разброса данных
		![[Pasted image 20250214164428.png]]
**Проблема выбросов**
	Если в данных есть *выбросы* - значения, которые гораздо выше или ниже остальных, - это может *негативно повлиять на среднее значение.*
	**Выброс** - наблюдение, которое сильно выделяется из общей картины для выборки.
	Таким образом, среднее значение на робастно, а медиана - напротив, выбросоустойчива.
	Выбросы могут отражать интересные события или *ошибки* в датасете, поэтому важно уметь определять их наличие.
	*Сравнение медианы и моды* - один из способов определить наличие выбросов, хотя *визуализация* обычно позволяет это сделать быстрее.
	Поэтому ещё один вопрос, который необходимо задать: *насколько сильно разбросаны друг относительно друга значения?*
	Для ответа на такой вопрос существуют **МЕРЫ РАЗБРОСА**.
**Меры разброса (изменчивости)**
	1) max;
	2) min;
	3) Range (Размах) := max - min;
	4) Midrange := среднее от min и max;
	5) Inter-Quartile Range (Межквартильный размах);
	6) Low Spear Mid-spread High Spread;
	7) Variance (Дисперсия) и Standart Deviaton (Стандартное отклонение).
	**Размах и квартильный размах**
		Размах (Range) - разность максимального и минимального значений вариоционного ряда.
		Характеристика разброса данных в выборке - **квартильный (или межквартильный) размах**. Он основывается на понятии *квартилей*.
		**Квартиль** - значение, которые делят выборку на 4 равные (по количеству объектов) части.
		Под *квартилями* понимают значения $Q_{1}, Q_{2}, Q_{3}$ которые делят вариационный ряд на четыре равные части.
		**Размах квартилей** - разница между $Q_{3}\ и\ Q_{1}$
	![[Pasted image 20250221153713.png]]
**Классификация выбросов**
	Классифицируют два вида выбросов: *умеренные* и *экстримальные*.
	*Умеренными* называют выбросы, которые удалены ниже первой квартили или выше третьей от 1.5IQR, но не более, чем на 3IQR. *Экстримальные выбросы* удалены ниже первой квартили или выше третьей более, чем на 3IQR. Схема определения выбросов приведена на рисунке. Определение выбросов крайне важно на этапе подготовки данных и позволяет избавиться от значений, достоверность которых соминтельна.
	![[Pasted image 20250221154204.png]]
**Метод межквартильных размахов (IQR)**
	Чтобы справиться с выбросами, можно либо *отбросить выбросы*, либо *заменить выбросы*, используя *метод межквартильных размахов (IQR)*.
	В EDA вычислить IQR для выявления закономерностей путем нахождения разницы между 25-м и 75-м процентилями данных.
	**Процентиль** - делит данные на 100 частей.
	IQR используется для выявления выбросов путём определения пределов для значений выборки , которые являются фатором k IQR. Общим значением для фактора k является значения 1.5.
	![[Pasted image 20250221154551.png]]
**Дисперсия**
	**Дисперсия** - измеряет *отклонение* значений относительно *среднего*.
	$$\sigma^2 = \frac{\Sigma_{i=1}^n(x_{i}-x)^2}{n}$$
	**Дисперсия** - это среднеквадратичное значение отклонений каждой из величин от среднего
	**Стандартное отклонение**
		**Стандартное отклонение (st-dev)** - мера разброса точек данных. Оно измеряет изменчивость путём вычисления среднеквадратичного расстояния между наблюдениями и средним значением из набора данных.
		$$\sigma = \sqrt{\frac{\Sigma_{i=1}^n(x_{i}-x)^2}{n}}$$
		**Стандартное отклонение** измеряет *отклонение* значений *относительно среднего значения*.
		На практике чаще используется именно *стандартное отклонение*, т.к. оно выражает *изменчивость в исходных единицах измерения признака*
**Меры центральной тенденции**
	Если *распределение симметричное*, то мода, медиана и среднее совпадают.
	Чем *больше отклонение от симметричности*, тем больше расхождение между значениями этих мер центральной тенденции. По этому расхождению можно судить о том, насколько симметрично или асимметрично распределение.
**Нормализация данных**
	**Нормализация данных** - процесс преобразования значений признаков данных так, чтобы они находились в одном диапазоне, что особенно важно, поскольку исходные диапазоны признаков могут сильно варьироваться.
	Нормализация предполагает изменение исходного диапазона значений признака на диапазон с заданным минимум и максимум, например $[0, 1]$ или $[-1, 1]$. Такой подход позволяет нормализовать дисперсию между признаками в наборе данных, которая в противном случает может оказаться преувеличенной вследствии влияния того или иного фактора.
	$$X_{norm} = \frac{X-X_{min}}{X_{max}-X_{min}}$$
	![[Pasted image 20250221160042.png]]
**Стандартизация данных (Z-преобразование)**
	Более эффективный метод подчёркивания *высоких* или *низких значений признака* - **стандартизация**, при которой данные преобразуются так, чтобы иметь *среднее значение 0 и стандартное отклонение 1*. Это будет означать, что *чрезвычайно высокое или низкое значение* будет выражено в виде трех или более стандартный отклонений от среднего.
	Стандартизация полезна когда:
		1) данные имеют *разные размеры* и *единицы измерения*;
		2) выбросы важны и должны быть учтены, но важно заставить модель сосредоточиться на относительных различияхю
	![[Pasted image 20250221160419.png]]
	![[Pasted image 20250221160520.png]]
	Эта формула эффективно маштабирует данные, *центрируя их вокруг 0 и корректируя разброс на основе стандаратного отклонения*.
	**Стандартизацию** рекомендуют выполнять при подготовке данных для последующего использования *регрессии, машин опорных векторов (SVM), метод k-ближайших соседей (k-NN)* и выполнение *анализа главных компонент (PCA)*.
**Числовые сводки данных**
	**Меры центральной тенденции (Measure of Central Tendency)**: вычисляются, чтобы дать **центр**, вокруг которого распределены измерения в данных.
	**Меры вариации или изменчивости (Measure of Variation)**: описывают *разброс данных (изменчивость значений)* или насколько далеко измерения находятся от центра (среднего значения).
**Работа с дисперсией**
	**Что показывает дисперсия?**
		**Дисперсия в статистике** - это мера, которая показывает разброс между результатами. Если все они *близки к среднему*, **дисперсия низкая**. Если *результаты сильно различаются* - **дисперсия высокая**.
		Если говорить о всей выборке, дисперсия показывает, *насколько разнородны результаты*. Например, в *1 группе* почти все - шатены; во *2 группе* половина - шатены, а остальные блондины, рыжие.
	**Кто работает с дисперсией?**
		![[Pasted image 20250221161708.png]]
	**Связь с другими показателями**
		1) Среднее арифметическое;
		2) Стандартное отклонение;
		3) Смещение;
		4) Ошибка прогнозирования
**Разреженность в данных (Sparsity in Data)**
	Если большинство значений признаков отсутствуют, то данные называются **РАЗРЕЖЕННЫМИ**.
	Отсутствующие значения могут быть представленные как NAN, пусто, -, 0.
	Это может быть проблемой для многих стат. методов
	Если пропусков у признака-столбца слишком много (более 70%), то такой признак удаляют!
**Обработка пропущенных значений**
	![[Pasted image 20250221163008.png]]
	![[Pasted image 20250221163011.png]]
**Визуализация данных**
	**Визуализация данных** позволяет понять паттерны, тренды, взаимосвязи в данных через графику и диаграммы.
	![[Pasted image 20250221163241.png]]
# Машинное обучение. Контролируемое обучение (Supervised Learning (SL))
**Модель алгоритма**
	Решить задачу ML означает разработать алгоритм или модель алгоритма, зависящего от параметров и позволяющих определить значение метки класса (Y) для нового объекта (x).
	Моделью алгоритма a называется параметрическое семейство $g:X Y \ или\ g(x,\theta) $
	Процесс подбора оптимальной функции g и оптимальных параметров тета по обучащей выборке называют настройки (fitting, tuning) или обучение (traning) алгоритма a.
	**Признаковое описание объекта. Признаковое пространство.** Размерность признакового пространства определяется количеством признаков.
	**Признаки** объекта x можно записать в виде вектора $$x_{1},...,x_{d}$$
	**Обучающая выборка.**
		Матрица X

**О терминах, которые используются в ML**
	Пусть по характеристикам клиента (пол, возраст, средний доход, рейтинг кредитной истории и т.д.) нужно предсказать, вернёт клиент кредит или не вернёт.
	**Целевая переменная (target, y)**, т.е. величина, которую хотим предсказать - это число.
	Характеристики клиента, а именно, его пол, возраст, доход и т.д. называются **признаками (features)**.
	Сами же клиенты - сущности, с которыми работаем в этой задаче - называются **объектами (objects)**.
	**Обучающая выборка (traning, set).** Конечный набор объектов x, для которых известны значения целевой переменной y, т.е. все данные с *известными ответами* называются **обучающейся выборкой.**
	**Обучающая выборка** может быть разбита на несколько частей:
		1)**Тренировочная выборка:** используется непосредственно для обучения модели;
		2) **Валидационная выборка:** используется для настройки гиперпараметров и проверки качества модели в процессе обучения;
		3) **Тестовая выборка:** используется для окончательной оценки производительности модели на данных, которые не были использованы в процессе обучения.
**Оценка обобщающая способности модели ML**
	Одна из важных характеристик моделей ML - способность к обобщению (насколько хорошо модель работает на новых данных).
	Данные, на которых оцениваются качество модели, берут из первоначального датасета.
	Существует несколько подходов как *отщепить* часть данных.
	Рассмотрим два самых популярных из них:
		Отложенная выборка (held-out/hold-out set);
		Кросс-валидация (cross-validation).
**Обучение с учителем**
	В **обучении с учителем** набор данных организован как коллекция размеченных образцов  $$\{(x_{i},y_{i})\}^N_{i=1}$$ каждый элемент $x_{i}$ из N - вектор признаков.
	**Вектор признаков** - вектор, в котором каждое измерение $j=1,...,D$ содержит значение, описывающее некоторую характеристику образца.
	Признак обозначается как $X_{j}$
	**Метка y_{i}** м.б. элементом конечного множества классов {1,2,...,C} вещественным числом или более сложной структурой (вектор, матрица, дерево или граф).
	В области ML модель реализует *алгоритм ML.*
	В терминологии Scikit-Learn модели называются **оценщиками (estimator)**
	**Цель алгоритма обучения с учителем** - на основе набора векторов данных создать **модель**, которая принимает *вектор признаков x на входе* и возвращает информацию, которая позволяет определить *метку для этого вектора признаков.*
	![[Pasted image 20250307155053.png]]
	**Весь процесс ML делится на 2 этапа:** **ОБУЧЕНИЕ АЛГОРИТМА** и **ПРИМЕНЕНИЕ АЛГОРИТМА**
	**Общая схема решения задачи обучения с учителем:**
	1) Загрузить данные, выполнить их первичный анализ, выявить целевой признак;
	2) Предварительная обработка данных и EDA, разделить данные на обучающую и тестовую выборки;
	3) Построить модель с использованием различных множеств значений гиперпараметров;
	4) Оценить качество построенных моделей с использованием метрик; выбор лучшей модели;
	5) Применить модель для получения предсказаний.
	При решении задач классического ML наборы данных X и y как правило делятся ещё 2 части (как правило 80:20):
	$X_{train},X_{test}$ и $y_{train},y_{test}$
	![[Pasted image 20250307160252.png]]
	![[Pasted image 20250307160632.png]]
	![[Pasted image 20250307160834.png]]
	**Понятие гиперпараметров модели**
		Существуют два типа параметров ML:
			1) вычисляемые оценщиком в ходе своего обучения на основании предоставленных вами данных;
			2) задаваемые заранее при создании объекта оценщика Scikit-Learn, представляющего модель.
		Параметры, задаваемые заранее, называются **ГИПЕРПАРАМЕТРАМИ**
		**Гиперпараметр** - параметр, значение которого задаётся до начала обучения модели и не изменяется в процессе обучения. У модели может не быть гиперпараметра.
		**Параметр модели** - параметр, который изменяется и оптимизируется в процессе обучения модели, итоговое значение параметра - результат обучения модели.
**Основные проблемы ML**
	Недостаточный объём данных;
	Пропуски в данных;
	Переобучение (Overfitting);
	Недообучение (Underfitting).
	**Переобучение** - нежелательное явление, возникающее при решении задач обучения по прецедентам, когда вероятность ошибки обученного алгоритма на объектах тестовой выборки оказывается существенно выше, чем средняя ошибка на обучающей выборке. Переобучение возникает при использовании избыточно сложных моделей.
	**Недообучение** - нежелательное явление, возникающее при решении задач обучения по прецедентам, когда алгоритм обучения не обеспечивает достаточно малой величины средней ошибки на обучающей выборке. Недообучение возникает при использовании недостаточно сложных моделей.
**Линейные модели. Задача регрессии**
	Под задачей регрессии подразумевают определение математической модели (функции регрессии), устанавливающей функциональную связь между зависимой переменной и группой независимых переменных с учётом ошибки модели.
	**Регрессия в ML** - это задача ML с учителем, целью которого выступает установление взаимосвязей между различными переменными.
	**Регрессионный анализ**
		**Регрессионный анализ** - статистический инструмент для установления модели отношений между двумя переменными.
		Одна из этих переменных - предикторная переменная, значение которой собирается в ходе экспериментов.
		Другая переменная - переменной ответа, значение которой получено из переменной предиктора.
		В зависимости от форм мат. модели, которая используется для аппроксимации данных, регрессия бывает линейной и нелинейной.
		**ЛР** представляет собой статистический метод, который моделирует линейную зависимость между зависимой переменной и одной или несколькими независимыми переменными.
		Математически линейная зависимость представляет прямую линию, когда она изображена в виде графика.
		Нелинейная регрессия описывает нелинейные отношения между зависимой и независимой переменными.
		Нелинейное отношение, где показатель степени любой переменной не равен 1, создаёт кривую.
	**Ключевые термины**
		**Отклик (pesponse)**
			Переменная, которую пытаемся предсказать.
			*Синонимы*: зависимая переменная, Y-переменная, цель, исход.
		**Независимая переменная (independent variable)**
			Переменная, которая используется для предсказания отклика.
			*Синонимы*: независимая переменная, X-переменная, предиктор, признак, атрибут.
		**Запись (record)**
			Вектор, который состоит из значений предикторов и значений исхода для индивидуального элемента данных или случая.
			*Синонимы*: строка, случай, прецедент, образец, экземпляр, пример.
		**Пересечение (intercept)**
			Пересечение регрессионной прямой, т.е. предсказанное значение, когда X=0.
			*Синонимы*: точка пересечения.
		**Коэффициент регрессии (regression coefficient)**
			Наклон регрессионной прямой.
			*Синонимы*: наклон, оценка параметров, веса.
		**Подогнанные значения (fitted values)**
			Оценки полученные из регрессионной прямой.
			*Синонимы*: предсказанные значения.
		**Остатки (residuals)**
			Разница между наблюдаемыми значениями и подогнанными значениями.
			*Синонимы*: ошибки.
		**Наименьшие квадраты (least squares)**
			Метод подгонки регрессии путём минимизации суммы квадратов остатков.
			*Синонимы*: обычный метод наименьших квадратов или обычный МНК.
	**Постановка задачи регрессии**
		![[Pasted image 20250314152339.png]]
		![[Pasted image 20250314153037.png]]
	**Формальное определение линейной модели**
		Модель регрессии называется линейной, если значение предсказываемого признака Y вычисляется как сума известных признаков $X_{1}, X_{2},...,X_{m}$, взятых с некоторыми коэффициентами.
		$$y'=w_{1}x_{1}+w_{2}x_{2}+,...,+w_{m}x_{m}+w_{0}$$
		Линейная комбинация признаков для прогнозирования целевого значения.
		Задача заключается в нахождении оптимальных весов (коэффициентов).
		Парная и множественная регрессии помогают определить веса для каждой независимой переменной, которые минимизируют разницу между прогнозируемыми и наблюдаемыми значения зависимой переменной.
	**Минимизация эмпирического риска**
		Чаще всего при построении алгоритмов обучения используется метод минимизации эмпирического риска (средней ошибки алгоритма на обучающей выборке).
		Его суть состоит в том, чтобы для текущей модели подобрать алгоритм, минимизирующий значение средней ошибки на данной обучающей выборке.
		Этот подход может включать в себя разные функции потерь в зависимости от задачи ML.
		Функция потерь представляет собой метрику, которая в рамках оценки разности статистических заданных и полученных значений отражает отклонения результатов моделирования от реальных данных.
		Метод наименьших квадратов (МНК) - специфический случай минимизации эмпирического риска.
	**Линейная регрессия МНК (Ordinary Least Squares - OLS)**
		Метод наименьших квадратов (МНК) - метод нахождения оптимальных параметров линейно регрессии, таких, что сумма квадратов ошибок минимальна.
		Метод заключается в минимизации евклидова расстояния между двумя векторами - вектором восстановленных значений зависимой переменной и вектором фактических значений зависимой переменной.
		МНК важен в алгоритмах ЛР, потому что он позволяется:
			3) Минимизировать суммарные ошибки прогнозирования. Это помогает получить наилучшую линейную модель.
			4) Находить лучшую линию (или кривую), чтобы максимально точно описать связь между двумя переменными.
	**Метрики качества модели ML**
		В задачах ML для оценки качества моделей и сравнения различных алгоритмов используются метрики.
		Метрика - функция для определения расстояния между двумя элементами множества.
		Большинство метрики качества основано на понятии ошибки прогноза.
		- MAE
		- MSE
		- RMSE
		- MAPE
		- SMAPE
		- $R^2$
		Функция потерь (функция ошибки) - мера колич6ства ошибок, которые линейная регрессия делает на наборе данных.
		Хотя есть разные функции потерь, все они вычисляют расстояние между предсказанным значением y(x) и его фактическим значением.
		**Коэффициент детерминации $R^2$**
			Общая метрика регрессии - коэффициент детерминации.
			Значение находится в $[0;1]$. Это доля дисперсии зависимой переменной, объясняемая рассматриваемой моделью зависимости, т.е. объясняющими переменными.
			КД показывает количество объясненной дисперсии.
			КД численно показывает, сколько процентов разброса данных объяснила модель. Чем ближе к 1, тем лучше (но не всегда).
		**Среднеквадратичная ошибка**
			Метрика MSE вычисляется как сумма квадратов прогноза, деленная на количество точек тестовой выборки.
			Чем ближе прогнозы модели к наблюдениям, тем меньше будет MSE.
		**Корень среднеквадратичной ошибки**
			Метрика RMSE показатель, вычисляет корень из MSE.
			Чем ниже RMSE, тем лучше данная модель может "соответствовать" набору данных.
		**Средняя абсолютная ошибка**
			Метрика MAE вычисляет среднюю абсолютную разницу между прогнозом и фактом в наборе данных.
			Чем ниже MAE, тем лучше модель соответствует набору данных.
		**Средняя абсолютная ошибка в процентах**
			Метрика MAE в процентах.
		**Симметричная средняя абсолютная ошибки в процентах**
			SMAPE - мера точности, основанная на процентных ошибках. Т.е. абсолютная разность между наблюдаемым и предсказанным значениями делится на полу-сумму их модулей.
	**Модели регуляризации линейной регрессии: Lasso, Ridge, ElasticNet**
		**Регуляризация** в статистике, ML, теории обратных задач - метод добавления некоторых доп. ограничений к условию с целью решить некорректно поставленную задачу или предотвратить переобучение. Чаще всего эта информация имеет вид штрафа за сложность модели.
		Переобучению в большинстве случаем проявляется в том, что итоговые модели имеют слишком большие значения параметров. Соответственно, необходимо добавить в целевую функцию штраф.
		**Основные виды регуляризации**
			- L1
			- L2
			- ElasticNet
		**Мультиколлинеарность**
			Другая проблема, о которой следует знать, - это мультиколлинеарность.
			Если столбцы имеют высокую корреляцию, это может затруднить интерпретацию коэффициентов.
			На модель это обычно не влияет, влияет только на смысл коэффициента.
		**L1 (Lasso)**
			![[Pasted image 20250314162000.png]]
		**L2 (Ridge)**
			![[Pasted image 20250314162609.png]]
		**Норма**
			В математике норма вектора - его длина.
			В регрессионном анализе, чтобы соответствовать линейной модели, нужна мера несоответствия.
			Длина вектора в ML - ошибка в каждом обучающих данных (длина вектора, характеризующая разницу между истинным значением целевой переменной и значением, спрогнозированным моделью ML). Нужно измерить длину ошибки.
		**Отличие L2 от МНК**
			Коэффициенты $w_{1},w_{2},...$ выбираются согласно МНК, но далее корректируются так, чтобы каждый вес был близок к 0.
			Это означает, что каждый признак должен иметь как можно меньше влияние на результат.
		**Отличие L1 от L2**
			Основное отличие Lasso от Ridge - L1 может приводить обращение некоторых независимых переменных в ноль, тогда как L2 уменьшает их до значений, близких к нулю.
		**ElasticNet**
			Данный тип регуляризации учитывает эффективность обоих методов регуляризации L1 и L2, применяется в тех случаях, когда важно важно сохранить корреляционную связь переменных и не допустить зануление коэффициентов в регрессионной модели.
			![[Pasted image 20250314163912.png]]
		**Полиномиальная регрессионная модель**
			Модель полиномиальной регрессии частный случай модели линейной регрессии.
			Полиномиальная регрессия - алгоритм ML, используемый для прогнозирования.
			Один из распространенных шаблонов ML использование линейных моделей, обученных на нелинейных функциях данных.
			Базовая линейная модель не подходит для сложных данных (нелинейных) или поиска сложных отношений в наборе данных. Для решения подобных задач используется полиномиальная (нелинейная) регрессия.
			Один из способов учета нелинейной связи между предиктором и переменной отклика - использований полиномиальная регрессии:
			$$Y=\beta_{0}+\beta_{1}X+\beta_{2}X^2+...+\beta_{h}X^h+\epsilon$$
			где h - полиномиальная степень модели.
			При увеличении значения h, модель лучше соответствует нелинейным отношениям, но на практике редко выбираем h больше 3 или 4. За пределами этой точки модель становится слишком гибкой и подгоняет данные.
			**Полиномиальные признаки**
				Линейную регрессию можно расширить, построив полиномиальные признаки из коэффициентов.
				Полиномиальные признаки - признаки, созданные путем возведения существующих признаков в степень, т.е. создание новых входных признаков на основе существующих объектов.
			**Полиномиальная формула**
				$$f_{w,b}(X)=b+w_{1}X+w_{2}X^2+...+w_{d}X^d$$
				w - d-мерный вектор параметров;
				b - действительное число (смещение);
				d - полиномиальная степень модели.
**Задача классификации**
	Классификация - это одна из основных задач ML, которая заключается в предсказании категориального значения для входных данных на основе определённых признаков.
	Алгоритм, осуществляющий классификацию, называется классификатором.
	Классификация - раздел ML, посвящённый задаче построения алгоритма, классифицирующего произвольный объект на основе информации, полученной из обучающей выборки.
	**Постановка задачи классификации**
		Классификация - задача автоматического определения метки (класса) для неразмеченного образца.
		В ML задача классификации решается с помощью алгоритма обучения классификации, который на входе принимает набор размеченных данных и создает модель, которая принимает неразмеченный образец и возвращает либо его метку непосредственно, либо число, на основании которого аналитик сможет определить метку.
		Классовая принадлежность остальных объектов не известна. Требуется построить алгоритм, способный классифицировать произвольный объект из исходного множества.
	**Формальная постановка**
		Пусть
		**X** - множество описаний объектов;
		**Y** - конечное множество номеров (имён меток) классов.
		Существует неизвестная целевая зависимость - отображение $y*:X\rightarrow Y$, значения которой известны только на объектах конечной обучающей выборки.
		$$X^m=\{(x_{1},y_{1}),...,(x_{m},y_{m})\}$$
		Требуется построить алгоритм $a:X\rightarrow Y$, способный классифицировать произвольный объект $x\in X$
	В качестве целевого признака y в задаче классификации обычно выступают:
		- бинарный
		- категориальный
		- порядковый
	В задаче классификации метка является членом конечного множества классов.
	Если размер множества классов равен двум ("больной"/"здоровый"), то такая классификация называется бинарной классификацией (или биномиальной).
	Классификация с несколькими классами - это задача множественной классификации (мультиномиальная или многоклассовая).
	**Оценка эффективности модели классификации**
		- матрица ошибок (матрица неточности);
		- точность, полнота;
		- правильность;
		- F1-мера;
		- ROC-кривая.
		**Accuracy и precision (точность)**
			Accuracy (точность) - мера близости измерений к определенному значению, тогда как precision (точность) - близость измерений друг к друг, т.е. не обязательно к определенному значению.
			Другими словами: если есть набор точек данных, полученных в результате повторных измерений одной и той же величины, набор считается точным, если их среднее значение близко к истинному значению измеряемой величины.
			С другой стороны, набор точный, если значения близки друг к другу.
			Эти две концепции независимы друг от друга, а это означает, что набор данных может быть accurate (точным) или precise (точным), или и тем, и другим, или ни одним из них.
			**MOODLE PHOTO**
		**Confusion Matrix (confusion_matrix)**
			Confusion Matrix (матрица ошибок) - таблица, описывающая успешность классификации данных, принадлежность разным классам.
			Используется для визуализации производительности классификатора.
			Особенности:
				- для двух классов ошибок представляет собой таблицу 2x2, для трёх классов - 3x3 и т.д.
				- Матрица ошибок разделена на 2 измерения: прогнозируемые значения и фактические значения, общее количество прогнозов.
				- Прогнозируемые значения - это значения, которые прогнозируются моделью, а фактические значения - истинные значения для данных наблюдений.
			**Необходимость матрицы ошибок**
				Оценивает производительность моделей классификации, когда они делают прогнозы на основе тестовых данных, и сообщает, насколько хороша модель классификации.
				Сообщает не только ошибку, допущенную классификаторами, но и тип ошибки, например 1-го рода или 2-го рода.
				С помощью матрицы ошибок можно рассчитать различные параметры модели, например, accuracy, precision.
		**Precision (Точность) (precision_score)**
			Точностью (precision) называется доля правильных ответов модели в пределах класса, т.е. это доля объектов действительно принадлежащих данному классу относительно всех объектов, которые система отнесла к этому классу.
			$$precision=\frac{TP}{TP+FP}$$
			Именно введение precision не позволяет записывать все объекты в один класс, т.к. в этом случае получим рост уровня FP (False Positive).
		**Критерии качества классификации**
			- Точность (precision)
			- Полнота (recall)
			Желательно, чтобы precision и recall были близки к 1.
		**Recall (Полнота) (recall_score)**
			Полнота - доля истинно положительных классификаций. Полнота показывает, какую долю объектов, реально относящихся к положительному классу, предсказана верно.
			$$recall=\frac{TP}{TP+FN}$$
			Полнота демонстрирует способность алгоритма обнаруживать данный класс вообще.
		Имея матрицу ошибок, можно вычислить точность и полноту для каждого класса.
			**Точность** - отношение соответствующего диагонального элемента матрицы и суммы всей строки класса.
			**Полнота** - отношение диагонального элемента матрицы и суммы всего столбца класса.
			$$precision_{c}=\frac{A_{c,c}}{\Sigma_{i=1}^nA_{c,i}}$$
			$$recall_{c}=\frac{A_{c,c}}{\Sigma_{i=1}^nA_{i,c}}$$
		**Accuracy (точность, корректность) (accuracy_score)**
			Accuracy - статистическая мера, определяемая как частное отношение правильных прогнозов (TP), так и истинно отрицательных (TN), сделанных классификатором, к сумме всех прогнозов, сделанных классификатором, включая ложные срабатывания (FP) и ложноотрицательных результатов (FN).
			$$accuracy=\frac{TP+TN}{TP+TN+FP+FN}$$
		**F-мера (F-score) f1_score**
			**Precision** и **recall** не зависят, в отличие от accuracy, от соотношения классов и потому применимы в условиях несбалансированных выборок.
			Часто в реальной практике стоит задача: найти оптимальный баланс между этими двумя метриками. Но в реальной жизни максимальная точность и полнота не достижимы одновременно и приходится искать некий баланс. Поэтому, хотелось бы иметь некую метрику, которая объединяла бы в себе информацию о точности и полноте нашего алгоритма. Именно такой метрикой является F-мера.
			F-мера - гармоническое среднее между точностью и полнотой. Она стремится к нулю, если точность или полнота стремится к нулю.
			$$F=\frac{2*precision*recall}{precision+recall}$$
			Эта формула придаёт одинаковый вес точности и полноте, поэтому F-мера будет падать одинаково при уменьшении и точности и полноты.
		**Кривая ROC**
			Кривая ROC иллюстрирует работу классификатора, отслеживая частоту истинно позитивных результатов при изменении частоты ложно позитивных. Кривая представляет из себя линию от (0,0) до (1,1) в координатах TPR и FPR.
			**TPR** - процент среди всех positive верно предсказан моделью.
			$$TPR=\frac{TP}{TP+FN}$$
			**FPR** - процент среди всех negative неверно предсказан моделью.
			$$FPR=\frac{FP}{FP+TN}$$
			Прямая линия по диагонали представляет ROC-кривую классификатора. Хороший классификатор держится от указанной линии настолько далеко, насколько это возможно (стремясь к левому верхнему углу).
			**ВСТАВИТЬ ФОТО ИЗ ЛЕКЦИИ (ТЕЛЕФОН)**
		**Проблема дисбаланса классов**
			Метрика **accuracy** бесполезна в задачах с неравными или несбалансированными классами (imbalanced class).
			Как вариант - можно исправить с помощью алгоритма сэмплирования.
			**Сэмплирования** (data sampling) - метод корректировки обучающей выборки с целью балансировки распределения классов в исходном наборе данных.
				Когда в обучающем наборе данных доля примеров некоторого класса слишком мала, такие классы называются *миноритарными (minority)*, другие, со слишком большим количеством представителей - *мажоритарными (majority)*.
			Значимость ошибочной классификации может быть разной.
			Неверная классификация примеров миноритарного класса, как правило, обходятся в разы дороже, чем ошибочная классификация примеров мажоритарного класса.
		**Стратегии сэмплирования**
			**Субдискретизация** (under-sampling) - удаление некоторого количества примеров мажоритарного класса.
			**Передискретизация** (over-sampling) - увеличение количества примеров миноритарного класса.
			**Комбинирование** (combining over- and under-sampling) - последовательное применение субдискретизации и передискретизации.
			**Ансамбль сбалансированных наборов** (ensemle balanced sets) - метод, при котором в процессе формирования ансамблей классификатором применяются встроенные методы сэмплирования для достижения более равномерного распределения классов в обучающих выборках.
		**Неравномерное распределение классов**
			1. Недостаточное представление класса в независимой переменной.
				Этот случай возникает, когда данные, используемые для построения модели, не покрывают все возможные варианты или характеристики независимой переменной, которые могут быть важны для целевой переменной.
			2. Недостаточное представление класса в зависимой переменной.
				Этот случай имеет место, когда в исходных данных, используемых для обучения модели, определенный класс целевой переменной представлен в недостаточном количестве по сравнению с другими классами.
			Неравномерное распределение классов в данных может привести к проблемам при обучении моделей, особенно в контексте задач классификации в ML.
			Подходы для решения проблем, связанных с недостаточным представление классов в независимой и зависимой переменной.
				1. Недостаточное представление класса в независимой переменной.
					- Сбор доп. данных;
					- Аугментация данных;
					- Использование методов перебалансировки:
						Oversampling: увеличение количества экземпляров менее представленных классов.
						Undersampling: уменьшение количества экземпляров более представленных классов.
				2. Недостаточное представление класса в зависимой переменной.
					- Использование специализированных алгоритмов.
					- Синтетические данные.
		**Алгоритмы сэмлирования**
			**Субдискретизация**
				- **RandomUnderSampling**. Рассчитывается число K - количество мажоритарных примеров, которое необходимо удалить для достижения требуемого уровня соотношения различных классов. Затем случайным образом выбираются K мажоритарных примеров и удаляются.
				- **NearMiss**. Этот метод выбирает примеры мажоритарного класса, основываясь на расстоянии до миноритарного класса. Он может использовать разные стратегии, такие как выбор ближайших соседей.
				- **Tomek Links**. Использует метод удаления объектов из мажоритарного класса, которые образуют "Томекские ссылки" с миноритарным классов.
			**Передискретизация**
				- **RandomOverSampling**. Этот метод случайно дублирует примеры миноритарного класса, чтобы сбалансировать классы.
				- **SMOTE**. Генерирует синтетические примеры миноритарного класса, основываясь на существующих точках.
				- **ADASYN**. Подобно SMOTE, но создаёт больше примеров в тех областях, где требуется больше.
			**Комбинирование**
				- **SMOTEENN**. Комбинирует SMOTE для увеличения миноритарного класса и метод kNN для удаления "шумных" примеров.
				- **SMOTETomek**. Сначала применяет SMOTE, а затем применяет Tomek Links для очистки набора данных.
			**Ансамбль сбалансированных наборов**
				- **BalancedBaggingClassifier**. Использует метод подбора сбалансированных выборок при создании ансамбля классификатора.
				- **BalancedRandomForestClassifier**. Включает в бея методы передискретизации, перебирая сбалансированные наборы для создания леса.
	**Линейная модель классификации**
		**Логистическая регрессия**
			Логистическая регрессия - это не регрессия, а алгоритм обучения классификации.
			Название происходит из статистики и связано с тем, что математическая формулировка логистической регрессии аналогична линейной регрессии.
			Логистическая регрессия - это алгоритм классификации, который предсказывает вероятность принадлежности объекта к определённому классу.
			В отличие от линейной регрессии, которая предсказывает числовые (непрерывные) значения, логистическая регрессия выдаёт вероятности (от 0 до 1) с помощью сигмоидной функции (также известна как логистическая, или логит-функция).
			**Цель** - вычислить вероятность того, данное исходное значение принадлежит к определённому классу.
			Логистическая регрессия использует для задач классификации: оценивает апостериорные вероятности принадлежности данного объекта к тому или иному классу.
			Отличительная черта логистической регрессии - значением функции является вероятность.
			На входе логистической регрессии, как и линейная, принимает одну или несколько независимых переменных и подсчитывает их взаимосвязь с зависимой переменной. Различие в том, что логистическая регрессия применяет сигмоидною функцию, которая позволяет предсказывать непрерывную переменную со значениями на отрезке $[0, 1]$ при любых значениях независимых переменных. Фактически это распределение Бернулли.
			**Правило классификации**
				Допустим объект А описывается признаками $(x_{1},x_{2},...,x_{n})$
				Объект А принадлежит классу 1, если $x_{1}w_{1}+x_{2}w_{2}+...+x_{n}w_{n}>0$
				Объект А принадлежит классу -1, если $x_{1}w_{1}+x_{2}w_{2}+...+x_{n}w_{n}<0$
				Числа $w_{i}$ являются параметрами модели и настраиваются по тренировочной выборке.
				Примечание: в теории линейной классификации классы удобнее обозначать через 1 и -1
			**Математическая основа**
				Сигмоидная функция (сигмоид)
				Функция, которая преобразует линейную комбинацию признаков в вероятность: $$\sigma(z)=\frac{1}{1+e^{-z}}$$
				где $z=w_{0}+w_{1}z_{1}+...+w_{n}z_{n}$ - линейная комбинация признаков.
				w - веса модели,
				z - признаки объекта.
				**ВСТАВИТЬ ФОТО ИЗ ТЕЛЕФОНА (ГРАФИК)**
			**Практическое значение свойств сигмоида:**
				Калибровка вероятностей: сигмоида преобразует любые значения $z\ (от -\inf\ до\ +\inf)$ в интервал $[0, 1]$, что позволяет интерпретировать выходы как вероятности.
				Порог классификации: обычно порог выбирает 0.5, но его можно менять в зависимости от задачи (например, для минимизации ложных срабатываний).
				Чувствительность к весам:
					- Большие положительные веса w сдвигают z в плюс бесконечность, следовательно предсказание класса 1.
					- Большие отрицательные веса w сдвигают z в минус бесконечность, следовательно предсказание класса 0.
			**Модель логистической регрессии**
				$$y\_pred=logistic(f_{\theta}(x))=\frac{1}{1+e^{-f_{\theta}(x)}}$$
				$$logistic(x_{1}w_{1}+w_{0})=\frac{1}{1+e^{-x_{1}w_{1}-w_{0}}}$$
				Результат f(x) можно интерпретировать как вероятность, что $y_{i}$ будет иметь положительное значение.
			**Логистическая функция ошибок (log_loss)**
				В логистической регрессии функция потерь, известная как логарифмическая потеря (log_loss), используется для оценки качества модели при классификации. log_loss измеряет разницу между предсказанными вероятностями и фактическими метками классов. Метрика определяет среднее расхождение между вежду вероятностями отнесения объектов к конкретным классам и их действительными классами:
				$$log\_loss=-\frac{1}{n}\Sigma_{i=1}^n[actual_{i}*log(predicted_{i}) + (1-actual_{i})*log(1-predicted_{i})]$$
				где
				$actual_{i}$ - истинная метка класса для i-го объекта;
				$predicted_{i}$ - вероятность отнесения $y_{i-го}$ объекта к классу "1";
				n - количество объектов.
				**Функцию необходимо минимизировать!!!**
				"Эту функцию называют также перекрёстной/кросс-энтропией (Cross Entropy) и часто используют в задачах классификации"
	**Метрический классификатор**
		Метрический классификатор - (similarity-based classifier) - алгоритм классификации, основанный на вычислении оценок сходства между объектами.
		Для формализации понятия сходства вводится функция расстояний между объектами $p(x,x')$
		Считается, что если две точки близки, то их признаки похожи. Такие модели , основанные на расстоянии - метрические модели.
		Метрические классификаторы опираются на гипотезу компактности, которая предполагает, что схожие объекты чаще лежат в одном классе, чем в разных. Это означает, что граница между классами имеет достаточно простую форму, и классы образуют компактно локализованные области в пространстве объектов.
		**kNN**
			kNN - алгоритм ML, используемый для задач классификации и регрессии
			Принцип работы:
				Для нового объекта ищутся k ближайших (по выбранной метрики расстояния) объектов из обучающей выборки.
				В классификации выбирается класс, наиболее часто встречающийся среди этих соседей.
				В регрессии возвращаются средние (или взвешенное среднее) значений целевой переменной соседей.
			Метод kNN - для повышения надёжности классификации объект относится к тому классу, которому принадлежит большинство из его соседей - k ближайших к нему объектов обучающей выборки $x_{i}$.
			В задачах с двумя классами число соседей берут нечётным, чтобы не возникало ситуаций неоднозначности, когда одинаковое число соседей принадлежит разным классам.
			Метод взвешенных ближайших соседей - в задаче с числом 3 и более нечётность уже не помогает и ситуации неоднозначности всё равно могут возникать. Тогда i-ому соседу приписывается вес $w_{i}$, как правило, убывающей с ростом ранга соседа i. Объект относится к тому классу, чей вес наибольший.
			**Описание алгоритма**
				Пусть задача обучающая выборка пар "объект-ответ"
				$$X^m=\{(x_{1},y_{1}),...,(x_{m},y_{m})\}$$
				Пусть на множестве объектов задана функция расстояния $p(x, x')$
				Эта функция должна быть достаточно адекватной моделью сходства объектов. Чем больше значение этой функции, тем менее схожими являются два объекта.
				Для произвольного объекта u расположим объекты обучающей выборки $x_{i}$ в порядке возрастания расстояний до u:
				$$p(u,x_{1;u})<=p(u,x_{2;u})<=...<=p(u,x_{m;u})$$
				где через $x_{i;u}$ обозначается тот объект обучающей выборки, который является i-м соседом объекта u. Аналогичное обозначение введём и для ответа на i-м соседе: $y_{i;u}$. Таким образом, произвольный объект u порождает свою перенумерацию выборки.
			**Особенности работы алгоритма kNN**
				Если значения признаков непрерывные, то в качестве меры расстояние между объектами обычно используется расстояние Евклида, а если категориальные, то может использоваться расстояние Хэмминга.
				Алгоритм kNN является чувствительным к дисбалансу классов в обучающих данных: алгоритм "склонен" к смещению решения в сторону доминирующего класса, поскольку относящиеся к нему объекты просто чаще попадают в число ближайших соседей.
			**Проблема kNN**
				Если признаков слишком много, а расстояние вычисляется как сумма отклонений по отдельным признакам, то возникает *проблема проклятия размерности.* Суммы большого числа отклонений с большой вероятностью имеют очень близкие значения. Получается, что в пространстве высокой размерности все объекты примерно одинаково далеки друг от друга; в частности, выбор ближайших соседей становится практически случайным.
				Проблема решается путём отбора относительно небольшого числа информативных признаков (features selection) и уменьшение размерности (PCA, t-SNE): рекомендуется использовать только те входные переменные, которые наиболее важны для прогнозирования выходной переменной.
			**Преимущества**
				- Простой в реализации
				- Не требует обучения
				- Гибкость
					Можно использовать для решения задач как классификации, так и регрессии.
				- Отсутствие предположений о распределении данных
			**Недостатки**
				- Высокая вычислительная сложность
					При больших объёмах данных kNN может быть медленным, т.к. требует вычисления расстояний до всех обучающих примеров.
				- Проблема с масштабированием
					Алгоритм чувствителен к масштабированию признаков. Необходимо нормализовать данные перед применением kNN.
				- Чувствителен к шуму
					Наличие выбросов или шумов в данных может негативно сказаться на качестве классификации.
				- Проблема с выбором параметра k
					Все признаки считаются одинаково значимыми.
				- Плохо работает с несбалансированными классами
					Если классы в данных сильно несбалансированы, kNN может отдавать предпочтение более распространённому классу
				- Чувствителен к проклятию размерности
			**Области применения kNN**
				- Классификация текстов
				- Рекомендательные системы
				- Обработка изображений
				- Медицинская диагностика
				- Анализ данных
	**Наивный байесовский классификатор (Naive Bayes Classifier NBC)**
		Наивный байесовский классификатор - очень популярный алгоритм классификации в ML, основанный на теореме Байеса с допущением о независимости признаков.
		Как следует из названия, этот алгоритм делает предположение, что все переменные в наборе данных "наивные", т.е. не коррелируют друг с другом.
		НБК - вероятностный алгоритм ML, используемый в самых разных задачах классификации.
		Модель НБК основывается на двух ключевых компонентах, вычисляемых непосредственно из обучающих данных:
			- Априорные вероятности (Prior Probabilities) каждого класса;
			- Условные вероятности (Likelihood) признаков для каждого класса
		После оценки этих вероятностей модель применяет т. Байеса для предсказания класса новых наблюдений. Прогнозирование осуществляется посредством вычисления апостериорной вероятности по т. Байеса.
		**Математическая основа**
			В основе НБК лежит т. Байеса, которая позволяет рассчитать апостериорную вероятность P(c|x) на основе P(c), P(x) и P(x|c).
			Апостериорная вероятность - условная вероятность случайного события при условии того, что известны апостериорные данные (т.е. полученные после опыта).
			**ВСТАВИТЬ ФОТО ИЗ ТГ**
		**Типы НБК**
			- Мультиномиальный (Multinomial NBC): здесь векторы признаков представляют собой значения частотности, т.е. частоту, с которой генерируются те или иные события посредством мультиномиального распределения. Это модель событий, обычно используется для классификации документов.
			- Complement NBC: вариация НБК, специально разработанный для работы с несбалансироваными наборами данных. В отличие от стандарнтого мультиномального НБК, который может быть смещён в сторону доминирующих классов, CNBC использует "дополняющую" статистику, чтобы уменьшить это смещение. Используется в текстовой классификации.
			- Бернули (BNBC): в многомерной модели событий Бернулли характеристики являются независимыми логическими значениями, которыми описываются входные данные. Подобно мультиномиальной модели, эта модель широко применяется в задачах классификации документов, где используется не частотность термина.
			- Гаусса (GNBC): предполагается, что непрерывные значения всех характеристик имеют распределение Гаусса.
		**Преимущества**
			- Высокая скорость работы;
			- Простота реализации;
			- Хорошая работы с малыми данными;
			- Устойчивость к шумам;
			- Подходит для многоклассовых задач;
			- Низкая склонность к переобучению.
		**Недостатки**
			- "Наивное" предположение о независимости признаков;
			- Проблема "нулевой вероятности";
			- Чувствительность к распределению данных;
			- Не оценивает важность признаков;
			- Не подходит для сложных зависимостей.
		**Области применения**
			- Текстовая классификация;
			- Многомерные данные;
			- Когда важна интерпретируемость;
			- Можно использовать его для многоклассовых прогнозов в реальном времени, классификация текстов, фильтрация спама, анализа настроения и многого другого.
	**Машина опорных векторов (Support Vector Machines SVM)**
		SVM - модели ML с учителем, используется как для классификации, так и для регрессии. Хотя SMV преуспевает в задачах классификации. (SVR/SVC)
		SVM - алгоритм ML, который классифицирует данные путём нахождения оптимальной линии или гиперплоскости, которая максимизирует расстояние между каждым классом в N-мерном пространстве.
		Данный метод классификации, который ищет гиперплоскость, разделяющую классы с максимальным зазором (маржей).
		Цель алгоритма SVM: найти линию (границу решения), которая может разделить N-мерное пространство на классы, чтобы можно было поместить новые точки данных в правильный класс. Эта граница решения называется гиперплоскостью.
		Цель SVM как классификатора: найти уравнение разделяющей гиперплоскости $w_{1}x_{1}+w_{2}x_{2}+...+w_{n}x_{n}+w_{0} = 0$ в пространстве $R^n$, которая бы разделила два класса неким оптимальным образом.
		Общий вид преобразования F объекта x в метку класса Y: $F(x)=sign(w^{T}x-b)$, где $w=(w_{1},w_{2},..,w_{n}),b=-w_{0}$
		После настройки весов алгоритма обучения w и b, все объекты, попадающие по одну сторону от построенной гиперплоскости будут предсказываться как первый класс +1, а объекты, попадающие по другую сторону - второй класс -1.
		**ВСТАВИТЬ ФОТО ИЗ ТГ**
		**Маржа (margin)** - зазор между гиперплоскостью и опорными векторами. Рассчитывается как перпендикулярное расстояние от линии до опорных векторов или ближайших точек данных.
		**Гиперплоскость (hyperplane)** - границы (плоскость) принятия решений, которые помогают классифицировать точки данных.
		**Опорные векторы (support vectors)** - точки данных, которые находятся на гиперплоскости или находятся ближе всего к ней и влияют на положение гиперплоскости. Разделительная линий будет определятся с помощью этих точек.
		**ЦЕЛЬ SVM** - максимизировать расстояние зазора (между ближайшими точками разных классов (опорными векторами))
		Чем больше зазор, тем меньше будет средняя ошибка классификатора.
		**Лучшая гиперплоскость** - это та плоскость, которая находится на максимальном расстоянии от обоих классов, что является главной целью SVM. Это делается путем поиска различных гиперплоскостей, которые классифицируют метки наилучшим образом, а затем выбирается та, которая находится дальше всего от точек данных или та, которая имеет максимальный запас.
		**Maximum Margin Classifier (MMC)**
			ММС - это гиперплоскость, которая среди всех разделяющих гиперплоскостей находят ту, которая создаёт наибольший зазор между двумя классами.
		**Ключевые свойства SVM**
			Если классы не разделяются линейно, то в SVM применяют:
				1. Kernel trick
				2. Вводят величину штрафа за каждый неправильно классифицированный объект.
			SVM классифицирует линейно разделимые данные по различным классам, находя наиболее подходящую гиперплоскость, иначе можно использовать "трюк с ядром", чтобы заставить его работать, если данные не являются линейно разделимыми
		**Жёсткая маржа (Hard margin SVM)**
			Жёсткая маржа: все точки должны находиться на правильной стороне гиперплоскости и не могут пересекать её. Это подходит для линейно разделимых данных, но может быть проблематично в реальных сценариях, где данные могут быть шумными или неразделимыми.
			Используется в LSVM, когда данные являются линейно разделимыми. Это означает, что существует гиперплоскость, которая может разделить классы без ошибок.
			**Недостатки жёсткой маржи:**
				- Чувствительность к выбросам;
				- Сложность работы с неразделимыми данными.
		**Мягкая маржа (Sofr margin SVM)**
			Мягкая маржа: позволяет некоторым точкам данных находиться на неправильной стороне гиперплоскости, что делает модель более устойчивой к шуму и выбросам.
			В этом случае вводится параметр регуляризации C, который контролирует компромисс между максимизацией маржи и минимизацией ошибки.
			Выбор между жёсткой и мягкой маржей зависит от конкретной задачи и свойств данных. мягкая маржа чаще используется в практических приложения, т.к. она более гибкая и устойчивая.
			![[Pasted image 20250411152940.png]]
		**Функция потерь SVM (Hinge Loss, hinge_loss)**
			Hinge Loss (Шарнирная потеря) - способ измерения точности классифицирующей модели; штрафует модель, если предсказанные значения неверны или находятся слишком близко к границе решения. Широко применяется в задачах обучения с опорными векторами.
			Для задач бинарной классификации Hinge Loss может быть определена следующим образом$$L(y)=max(0,1-y\cdot f(x))$$
			где:
			$L(y)$ - значение функции потерь;
			$y$ - истинная метка класса (y=+-1);
			$f(x)$ - оценка модели для входных данных.
			Эта функция потерь равна 0, если модель правильно классифицировала пример, и увеличивается по мере того, как оценка модели становится менее уверенной или неверной.
		**Ядерные функции SVM**
			Для учета нелинейности обычно расширяют пространство переменных, включая разницу различные функциональные преобразования исходных предикторов (полиномы, экспоненты и т.д.).
			SVM как нелинейное обобщение линейного классификатора, основанное на расширении размерности исходного пространства предикторов с помощью специальных ядерных функций.
		**Трюк ядра (Kernel Trick, Kernel Function)**
			Нелинейно разделимые данные: иногда линейная граница просто не работает, независимо от значения C;
			Нужна нелинейная граница принятия решений!
			Отображение пространства более высокой размерности, поиск гиперплоскости и её проецирование обратно в пространство низкой размерности может потребовать больших вычислительных затрат.
			Решение: **kernel trick**
		**Ядро SVM**
			SVM использует технику, называемую трюком ядра для преобразования точек данных и создания оптимальной границы решения. Ядра помогают эффективно работать с многомерными данными.
			Ядерный трюк метод в ML, позволяющий перевести элементы для случая линейной неразделимости в новое линейно разделимое пространство. Такое пространство называют спрямляющими.
			**Ядро** - любая симметричная, положительно полуопределенная матрица K, составленная из скалярных произведений пар векторов $x_{i}$ и $x_{j}$.
			$K(x_{i},x_{j})=<\phi(x_{i}),\phi(x_{j})>$, характеризующих меру их близости. Здесь $\phi$ - произвольная преобразующая функция, формирующая ядро.
			Ядро определяет функцию сходства между объектами в новом пространстве признаков.
			Функция ядра используется для определения формы гиперплоскости и граница решения.
		**Типы ядер, используемые SVC**
			Функция ядра SVM для преобразования нелинейных данных в линейные:
				1. Линейное ядро;
				2. Полиномиальное ядро;
				3. Гауссово ядро с радиальной базисной функцией (RBF);
				4. Сигмоидное ядро;
				5. Ядро функции Бесселя;
				6. Ядро дисперсионного анализа;
				7. Формула ядра Anova.
		**Настройка гиперпараметров SVC**
			1. С (регуляризация) - стоимость неправильной классификации, размер штрафа;
			2. Ядро (kernel) каждое ядро имеет свои параметры, которые м.б. настроены для улучшения производительности модели;
			3. Гамма (Gamma) - отвечает за приближенность результирующей функций к датасету. Здесь нужно помнить, что при больших значениях гамма возможно переобучение.
			Перекрёстная проверка (CV) поиска по сетке используется для настройки гиперпараметров.
		**Линейное ядро (Linear kernel)**
			В линейном ядре функция ядра принимает форму линейной функции:$$Linear \ kernel:K(x_{i},x_{j})=x_{i}^{T}x_{j}$$
			Линейное ядро используется, когда данные линейно разделимы.
			Используется:
				- Когда большое количество объектов в наборе данных;
				- Для классификации текста.
			Обучение с линейным ядром быстрее, т.к. нужно оптимизировать только параметр регуляризации C.
			При обучении с другими ядрами необходимо оптимизировать параметр $\gamma$(gamma). Т.о., выполнение поиска по сетке обычно занимает больше времени.
		**Полиномиальное ядро (Polinomial kernel)**
			Полиномиальное ядро со степенью d: $$K(x_{i},x_{j})=(x_{i}^{T}x_{j}+1)^{d}$$
			Используется в обработке естественного языка (NLP). Наиболее распространенная степень d = 2, т.к. более высокие степени имеют тенденцию к переобучению в задачах NLP.
			Полиномиальные ядра дают хорошие результаты для задач, в которых все обучающие данные нормализованы.
		**Гауссово ядро с радиальной базовой функции (Radial Basis Function, RBF)**
			Ядро RBF - ядро общего назначения, используется, когда нет предварительных знаний о данных.
			Ядро RBF определяется уравнением: $$K(x_{i},x_{j})=exp(\gamma||x_{i}-x_{j}||^2)$$
		**Сигмоидное ядро (Sigmoid Kernel)**
			Сигмоидное ядро берет свое начало в нейронных сетях.
			Сигмоидное ядро задается уравнением: $$K(x_{i},x_{j})=tanh(\gamma x_{i}^Tx_{j}+\beta_{0})$$
			Сигмоидное ядро используется для моделирования нейронных сетей. Оно может работать с нелинейными данными, но не так эффективно, как RBF-ядро.
		**Преимущества SVM**
			- Эффективен в высокомерных пространствах;
			- Устойчив к переобучению;
			- Использует подмножество точек обучения в функции принятия решения, что обеспечивает эффективное использование памяти;
			- Хорошая устойчивость к выбросам;
			- Доказано, что SMV не слабее любой двуслойной нейросети.
		**Недостатки SVM**
				- Производительность не так хороша, когда набор данных большой, потому что время, необходимое для обучения больше;
				- Не подходит для нелинейных данных без ядер;
				- Не работает, если набор данных зашумлен;
				- Чувствителен к выбору гиперпараметра C.
	**Древовидные модели: решающие деревья и их композиции**
		**Дерево решений** - это непараметрический контролируемый метод обучения, используемый для классификации и регрессии. Чаще всего применяются для задач классификации.
		**Цель** состоит в том, чтобы создать модель, которая предсказывает значение целевой переменной путём изучения простых правил принятия решений, выведенных из характеристик данных.
		**CART (Classification and Regression Tree)** строит бинарные деревья, используя признак и порог, которые дают наибольший прирост информации в каждом узле.
		В настоящее время алгоритм DT известен своим современным названием **CART**.
		**Решающее дерево** предсказывает значение целевой переменной с помощью применения последовательности простых решающих правил. Этот процесс в некотором смысле согласуется с естественным для человека процессом принятия решений.
		**Древовидная модель** - это набор правил импликации вида *если-то-иначе*, которые просто понять и реализовать.
		Под *решающим правилом* понимается логическая конструкция в виде продукции.
		Продукционные правила представляются в виде *Если, То*.
		*Обобщающая способность DTs невысока*, но их предсказания вычисляются довольно просто, из-за чего DTs часто используют как "кирпичики" для построения *ансамблей* - моделей, делающих предсказания на основе агрегации предсказаний других моделей.
		**Древовидные модели** и их мощные потомки *случайные леса* и *бустинг* формируют основание для наиболее широко используемых и мощных предсказательных инструментов моделирования в науке о данных как для регрессии, так и для классификации.
		DTs способны обнаружить скрытые шаблоны (образы, паттерны), соответствующие сложным (нелинейным) взаимодействиям и нелинейные зависимости в данных.
		**Дерево классификации**
			**Особенности:**
				- Нелинейный классификатор;
				- Интерпретируемость;
				- Работает с числовыми данными в *sklearn*;
				- Встроенная поддержка пропущенных значений;
				- Вычисление:
					- Training: slow;
					- Prediction: fast
					- Глубина дерева, обычно не более 15
		**DT: Термины**
			В алгоритме существует древовидная структура, в которой каждый *внутренний узел (Decision Node)* представляет проверку атрибута, *каждая ветвь (Sub-Tree)* - результат проверка, а каждый *листовой узел (Leaf Node)* - метку класса.
			Пути от *корневого узла (Root Node)* к конечному узлу представляет собой правила классификации.
			![[Pasted image 20250418153353.png]]
			**Корневой узел (Root Node)** представляет всю совокупность или выборку. Далее это делится на 2 или более однородных набора.
			**Узел принятия решений (Decision node (internal node))**. Когда подузел разделяется на дополнительные подузлы, он называется *узлом принятия решений*.
			**Листовой/терминальный узел (Leaf node (terminal node))**. Узлы, которые не разделяются, называются *листовыми (терминальными узлами)*.
			**Разделение (Spliting)**. Это процесс разделения узла на 2 или более подузла.
			**Обрезка (Pruning)**. Когда удаляем подузлы узла решения, этот процесс называется *обрезкой*. Это противоположность процесс расщепления.
			**Ветка/поддерево (Sub-Tree)**. Подраздел всего дерева называется *ветвью (поддеревом)*.
			**Родительный и дочерний узел**. Узел, разделённый на подузлы, называется родительским узлом подузлов, где подузлы являются дочерними элементами родительского узла.
		**Ключевые термины**
			**Рекурсивное сегментирование (recursive partitioning)** - многократное разбиение данных на разделы и подразделы с целью создания максимально однородных исходов в каждом итоговом подразделе.
			**Значение в точке разбиения (split value)** - значение предиктора, которое делит записи на те, где этот предиктор меньше и где он больше значения в точке разбиения.
			**Потеря (loss)** - число неправильных результатов классификации на конкретном этапе в процессе разбиения; чем больше потерь, тем больше разнородность.
		**Процесс построения дерева решений**
			1. Для каждого атрибута в наборе данных алгоритм DT формирует *узел*. Самый важный атрибут размещается в *корневом узле*.
			2. Для оценки поставленной задачи старт с коревого узла и продвижения вниз по дереву, следуя за соответствующим *узлом*, который соответствует условию или решению.
			3. Этот процесс продолжается до тех пор, пока не будет достигнут *листовой узел*, содержащий прогноз DT.
			**Обучение на основе дерева решений** - это метод аппроксимации дискретных функций классификации с помощью древовидного представления.
			Обученное дерево решений классифицирует новый экземпляр, сортируя его по дереву:
				- *узел дерева* := классификация или проверка определенного атрибута экземпляра
				- *ветвь дерева* := возможное значение для рассматриваемого атрибута
			Полученное *дерево решений* можно представить как набор правил *Если, То*.
			"Зачитывать" правила из изученного дерева решений:
				- *узел дерева* := дизъюнкция поддеревьев
				- *ветвь дерева (поддерево)* := конъюнкция ограничений на значения атрибутов
			**Цель** - найти небольшое дерево соответствующее обучающим примерам.
			**Идея** - рекурсивно выбрать наиболее значимый атрибут в качестве корня (под)дерева.
		**Математическая формулировка**: https://scikit-learn.ru/stable/modules/tree.html#tree-mathematical-formulation
		**Общий алгоритм обучения дерева решений**
			- Выполнить статистический тест каждого атрибута, чтобы определить, насколько хорошо он классифицирует обучающие примеры, если рассматривать его отдельно.
			- Выбор лучшего признака для разделения данных на каждом узле DT:
				- Классификация:
					- логарифм потерь или энтропии
					- индекс Джини
				- Регрессии:
					- MSE
			- Рекурсивное разбиение до достижения критерия остановки. Определить узел-потомок по каждой ветви корня, отсортировать обучающие примеры в соответствии со значением, связанным с текущей ветвью, и повторить процесс, описанный в шагах 1 и 2.
		**Прирост информации (information Gain)**
			Прирост информации в качестве критерия оценки информации, содержащейся в каждом атрибуте.
			**Энтропия** используется для расчета прироста информации.
			Прирост информации - уменьшение энтропии. Прирост информации вычисляет разницу между энтропией до разделения и средней энтропией после разделения набора данных на основе заданных значений атрибутов. Энтропия выражается формулой:
			$$Entropy=\Sigma_{i=1}^{c}-p_{i}\cdot log_{2}(p_{i})$$
			с - количество классов;
			$p_{i}$ - вероятность, связанная с i-м классом
			Вычисляя уменьшение меры энтропии каждого атрибута, можно рассчитать его информационный прирост. Атрибут с наибольшим информационным приростом выбирается в качестве атрибута разделения в узле.
			Энтропия - это мера неопределенности в наборе данных.
		**Индекс Джини (gini)**
			Индекс Джини: это вероятность неправильной классификации случайной точки данных в наборе, если она была помечена на основе распределения классов набора данных. Измеряет степень неравномерности распределения классов.
			Подобно энтропии, если набор S является чистым, то его примесь равна нулю. Обозначается следующей формулой:
			$$G=1-\Sigma_{i=1}^cp_{i}^2$$
			где $p_{i}$ - доля класса i в узле
			Как для энтропии (H), так и для gini, 0 означает, что все элементы принадлежать к указанному классу.
		**Критерий классификации**
			Различные алгоритмы дерева решений используются разные показатели примесей.
			Измеряет примесь в наборе данных.
		**Эффективность алгоритма дерева решений**
			**Переобучение**
				Может привести к переобучению!
					- Дерево решений растет до тех пор, пока все обучающие примеры не будут идеально классифицированы.
					- Данные зашумлены.
					- Обучающий набор слишком мал, чтобы дать репрезентативную выборку целевой функции.
				**Регуляризация в деревьях решений** - это набор методов, направленных на уменьшение переобучения моделей и улучшения ее обобщающей способности. В отличие от некоторых других моделей, такие как линейные регрессии, деревья решений не имеют явных параметров для регуляризации, но есть несколько способов, которые можно использовать для достижения этой цели.
				**Настройка гиперпараметров**:
					- max_depth; 
					- max_features;
					- max_leaf_nodes;
					- min_impurity_decrease;
					- min_samples_leaf;
					- min_samples_split;
					- ccp_alpha;
					- criterion
	**Ансамблевое обучение**
		**Ансамблевое обучение** - обучение ансамблевой модели, т.е. комбинация нескольких базовых моделей ML, каждая их которых показывает худшее качество, чем их ансамбль.
		**Ансамбль моделей** - комбинация нескольких базовых моделей ML.
		**Идея**: вместо попыток создать одну высокоточную модель сосредоточиться на обучении множества моделей с относительно низкой точностью. Затем прогнозы полученные от этих "слабых" моделей, объединяются для формирования более точного и надёжного результата.
		Ансамблевое обучение даёт более точные (0.9 и выше) и более стабильные прогнозы, чем лучшая одиночная модель.
		Наиболее популярные виды ансамблевых методов:
			- **бэггинг**;
			- **бустинг**;
			- **стекинг**
		**Цель** - обучиться комбинировать сильные стороны базовых моделей.
		Три способа объединить слабо коррелированные модели в ансамблевую:
			- усреднение;
			- голосование;
			- штабелирование моделей (стекинг)
		Методы ансамблевого обучения основаны на:
			- Агрегация разнородных учащихся (voting classifiers/average predictions)
			- Агрегация однородных учащихся (bagging/boosting)
		**Метод простого голосования**
			$a_{1}, a_{2},...,a_{n}$ - несколько обученных алгоритмов.
			**Классификация**: относим x к классу, за который проголосовало большинство их $a_{1}(x), a_{2}(x),...,a_{n}(x)$
			**Регрессия**: ответом является среднее значение $a_{1}(x), a_{2}(x),...,a_{n}(x)$
		**Бэггинг**
			![[Pasted image 20250425153149.png]]
			**Бэггинг** (сокращение от **b**ootstrap **agg**regation)
			**Идея**: обучить несколько одинаковых моделей на основе различных случайных выборок из исходного набора данных. Распределение выборки неизвестно, поэтому модели получаются разными.
			Для начала генерируется несколько *бутстрэп-выборок*
			**Бутстрэп** - случайный выбор данных из датасета и представление их в модель, затем данные возвращаются в датасет и процесс повторяется. После модели делают свои прогнозы на основе бутстрэп-выборок.
			В случае регрессии прогнозы усредняются. В случае классификации применяется голосование.
			Бутстрэпная выборка для каждого дерева
			**Процедура Bagging**
				**Бутстрап-агрегирование (пакетирование)** - процедура общего назначения, позволяющая уменьшить дисперсию метода обучения и избежать переобучения.
				Учитывая обучающий набор, сначала создаём B случайные выборки (с заменой) обучающего набора.
				Для каждого образца b построить модель дерева решений $f_{b}$.
				После обучения получим B деревья решений. Прогнозы для нового тестового наблюдения x получаются как среднее значение прогнозов B (для регрессии) или большинства голосов (для классификации)
				$$y\leftarrow f(x)=\frac{1}{B}\Sigma^{b}_{b=1}f_{b}(x)$$
			**Идея**:
				1) Пусть обучающая выборка состоит из n объектов. Выберем из неё n примеров равновероятно, с возвращением. Получим новую выборку $X^1$, в которой некоторых элементов исходной выборки не будет, а какие-то могут войти несколько раз.
				2) С помощью некоторого алгоритма b обучим на этой выборке модель $b_{1}(x)=b(x,X^1)$.
				3) Повторим процедуру: сформируем вторую выборку $X^2$ из n элементов с возвращением и с помощью того же алгоритма обучим на ней модель $b_{2}(x)=b(x,X^2)$.
				4) Повторив процедуру k раз, получим k моделей, обученных на k выборках. Чтобы получить одно предсказание, усредним предсказания всех моделей:
				$$a(x)=\frac{1}{k}(b_{1}(x)+...+b_{k}(x))$$
			**Bagging RandomForest**
				**RF** представляет собой улучшение по сравнению с алгоритмом бэггинга за счёт использования небольшого трюка, который декоррелирует деревья.
				RF используется модифицированный алгоритм обучения дерева, который при каждом разбиении проверяют случайное подмножество объектов.
				Причина этого: избежать корреляции деревьев в лесу, таким образом базовые алгоритмы независимы.
				Чтобы получить хорошие прогнозы, RF должен состоять из разнообразного набора моделей. Вот почему каждое DT в модели использует для обучения разный набор признаков.
				![[Pasted image 20250425154530.png]]
				**Схема построения ансамбля алгоритмов.**
					1) Для построения i-го дерева решений:
						- Сначала, как в обычном бэггинге, из обучающей выборки X выбирается с возвращением случайная подвыборка $X^i$ того же размера, что и X.
						- В процессе обучения каждого дерева в каждой вершине случайно выбираются n<N признаков, где N - полное число признаков, и среди них ищется оптимальный сплит. Такой приём как раз позволяется управлять степенью скоррелированности базовых алгоритмов.
					2) Чтобы получить предсказание ансамбля на тестовом объекте, усредняем отдельные ответы деревьев или берём самый популярный класс.
					3) Построили RF - комбинации бэггинга и метода случайных подпространств над DTs.
				**Рекомендация** - брать **корень из числа всех признаков** для классификации и **треть признаков** для регрессии.
				**Гиперпараметры RF**
					- Максимальная глубина каждого дерева;
					- Максимальное количество конечных узлов;
					- Количество используемых деревьев (B);
					- Количество подмножества признаков;
					- Минимальный размер каждого узла (или листа);
					- Критерий: Джини, энтропия.
		**Бустинг**
			**Метод бустинга** похож на метод бэггинга: берётся множество одинаковых моделей и объединяется, чтобы получить сильного ученика.
			**Разница**: модели приспосабливаются к данным **последовательно**, т.е. каждая модель будет исправлять ошибки предыдущей.
			Базовые модели для бустинга: модели с низким разбросом (дисперсия) и высоким смещением. Например неглубокие DTs. Одна из причин такого выбора моделей: требует меньше вычислительных затрат.
			Два наиболее распространённых алгоритма бустинга:
				- Адаптивный бустинг;
				- Градиентный бустинг.
			**AdaBoosting**
				Лес слабых учеников (деревья только с 1 признаком (пни/stumps), т.е. 1 узел и 2 листа).
				Каждое дерево зависит от состояние предыдущей ошибки дерева решений.
				1) Начать с обычных критериев разделения;
				2) Каждое дерево решений получает разный вес w в зависимости от точности его прогноза.
				3) Каждое наблюдение получает вес w, обратно пропорциональный его прогнозируемому результату (например, неправильно классифицированные получают большой вес).
				4) Агрегация выполняется на основе веса w каждого слабого учащегося.
				Алгоритм сначала обучает 1-ю базовую модель на train наборе. Относительный вес некорректно предсказанных значений увеличивается. На вход 2-й базовой модели подаются обновлённые веса w и модель обучается, после чего вырабатываются прогнозы и цикл повторяется.
				Результат работы: средневзвешенная сумма каждой модели. Спрогнозированным значением ансамбля будет тот, который получает большинство взвешенных голосов:
				$$C=\Sigma_{i=1}^NW\cdot X$$
				C - результат работы ансамбля;
				W - вес;
				X - значение прогнозатора.
			**Градиентный бустинг над решающими деревьями (Gradient Boosting on DT, GBDT)**
				**GBDT** - один их самых универсальных и сильных методов ML, известных на сегодняшний день.
				**GBDT** - класс алгоритмов, представляющих бустинг как процесс градиентного спуска.
				В основе алгоритма лежит последовательное уточнение функции, представляющей собой линейную комбинацию базовых классификаторов. С тем чтобы минимизировать дифференцируемую функцию потерь.
				**BGDT** - метод ансамблевого обучения, который последовательно строит слабые модели (обычно DT), каждая из которых корректирует ошибки предыдущей.
		**Стекинг**
			**Стекинг (Stacking)** - алгоритм ансамблирования, основные отличия которого от предыдущих состоят в следующем:
				- Может использовать алгоритмы ML разного типа (т.е. разнородные (используют разный математический аппарат)), а не только из какого-то фиксированного семейства моделей ML.
				Например: в качестве базовых алгоритмов могут выступать kNN и линейная регрессия.
				- Результаты базовых алгоритмов объединяются в один с помощью обучаемой мета-модели, а не с помощью какого-либо обычного способа агрегации.
			**Мета-модель** - это модель, которая обучается на предсказаниях нескольких базовых моделей, чтобы улучшить общую производительность.